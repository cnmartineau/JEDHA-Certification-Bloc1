{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloc 1 - Construction et alimentation d'une infrastructure de gestion de données - Plan your trip with Kayak"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Kayak is a metasearch engine founded in 2004. The Kayak's website and mobile apps are available in about 30 countries and 20 languages to help travelers making decisions about their future trips.\n",
    "\n",
    "### Problematic\n",
    "\n",
    "Kayak discovered that their users would like to have more reliable information about their destination.\n",
    "\n",
    "The company marketing team would like to create an application based on the weather and on the hotels in the area, which would recommend the best destinations at any given time.\n",
    "\n",
    "### Scope\n",
    "\n",
    "The marketing team wants to focus on the top-35 places to visit in France, which are: Le Mont-Saint-Michel, Saint-Malo, Bayeux, Le Havre, Rouen, Paris, Amiens, Lille, Strasbourg, Le Château du Haut Koenigsbourg, Colmar, Eguisheim, Besancon, Dijon, Annecy, Grenoble, Lyon, Les Gorges du Verdon, Bormes-les-Mimosas, Cassis, Marseille, Aix-en-Provence, Avignon, Uzes, Nîmes, Aigues-Mortes, Saintes-Maries-de-la-mer, Collioure, Carcassonne, l'Ariège, Toulouse, Montauban, Biarritz, Bayonne, La Rochelle.\n",
    "\n",
    "### Aim and objectives\n",
    "\n",
    "Overall aim: Get weather and hotel data for these cities and make it available for the marketing team.\n",
    "\n",
    "Objectives:\n",
    "- 1 - Get gps coordinates for each destination.\n",
    "- 2 - Get weather data for each destination.\n",
    "- 3 - Get hotels' information for each destination.\n",
    "- 4 - Store all the information in a data lake.\n",
    "- 5 - Extract, transform and load cleaned data from the data lake to a data warehouse.\n",
    "- 6 - Provide a map of all destinations with weather information.\n",
    "- 7 - Provide maps of top-5 destinations with top-20 hotels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "## Methods\n",
    "\n",
    "### 1 - Library import and keys\n",
    "\n",
    "An API key was required to get data from openweathermap.org. Do not forget to input your own key if you wish to re-use the following code. The same goes for the access to your AWS account and to your database.\n",
    "\n",
    "### 2 - Gps coordinates\n",
    "\n",
    "The Kayak team asked for data about the top-35 cities to visit in France. However the provided destination list contained places that were not cities per se (i.e. Gorges du Verdon). Therefore the list was slightly modified to replace these few places by the closest or biggest city in the area. City names were corrected to fit the French ortograph.\n",
    "\n",
    "The gps coordinates (latitude and longitude) were extracted for the 35 cities with the API nominatim.org. A search by city name was used.\n",
    "\n",
    "### 3 - Weather forecast\n",
    "\n",
    "For each city, the weather data was extracted with openweathermap.org. The 5 days weather forecast API was chosen to obtain weather forecast from geographic coordinates for the 5 coming days with data every 3 hours. From the bunch of data that was available, the temperature (in degrees Celsius) and the probality of rain were selected as the most relevant to further choose top destinations based on the weather. Data was saved locally as a .csv file for future use (cnm_bloc1_data1_weather.csv).\n",
    "\n",
    "### 4 - Hotels\n",
    "\n",
    "For each city, accomodation data was scrapped from Booking.com. Since Kayak did not provide any criteria for hotel selection, the top-25 picks proposed by Booking.com were selected. Since some of the destinations are very small cities with few options for accomodation, the decision was made to not restrict the search to hotels but to also include other types of property such as bed and breakfasts or guesthouses in order to get the 20 accomodation options that were demanded. For the same reasons, nearby cities were also included.\n",
    "\n",
    "The scraping was performed in two steps. First, a list of urls corresponding to accomodation web pages (on Booking.com) was obtained and saved locally as .json file (cnm_bloc1_data2_urls.json). Then, information on each accomodation was scrapped from the accomodation pages. This way, the following information was gathered for each accomodation: name, address, Booking.com url, gps coordinates, score given by users, and text description. Data was saved locally as a .json file (cnm_bloc1_data3_hotels.json).\n",
    "\n",
    "### 5 - Data compilation and cleaning\n",
    "\n",
    "For all cities, data about weather and accomodations were loaded from the corresponding files and compiled in a single dataframe. \n",
    "\n",
    "Data was then cleaned as follow: correction of city names, fixing of formatting issues, dropping of accomodations for which no score was available, and selection of the top-20 accomodations per city based on user score.\n",
    "\n",
    "Data cleaning was checked and data was saved locally (cnm_bloc1_data4_final_dataset.csv) for future storage in a S3 bucket.\n",
    "\n",
    "### 6 - Maps\n",
    "\n",
    "The 35 cities were indicated on a map of France, with color indicating the probability of rain and size indicating the temperature forecasted for the 5 coming days.\n",
    "\n",
    "The top-5 cities were selected as those with the smallest probability of rain and the highest temperature. For each of them, a map with the location of the top-20 accomodations was provided.\n",
    "\n",
    "### 7 - Data storage and ETL\n",
    "\n",
    "Final cleaned data was stored in a S3 bucket as a .csv file, extracted from the S3 bucket, transformed into a dataframe, and loaded to a SQL database."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "## Conclusion\n",
    "\n",
    "The request of the marketing team to collect data from the web about weather and accomodations for the top-35 destinations in France was fulfilled.\n",
    "\n",
    "The cleaned collected data was transferred as a .csv file to a S3 bucket to then feed a SQL database."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "## Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Library import and keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1 - library import and keys - import libraries ### ----\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1 - library import and keys - input keys ### ----\n",
    "\n",
    "# WARNING! input your key for openweathermap.org here\n",
    "key_openweather = \"KEY\"\n",
    "\n",
    "# WARNING! input your credentials for aws\n",
    "aws_access_key_id=\"ACCESS_KEY\"\n",
    "aws_secret_access_key=\"SECRET_ACCESS_KEY\"\n",
    "\n",
    "# WARNING! input your access values to connect to your database\n",
    "dbuser = \"USERNAME\"\n",
    "dbpass = \"PASSWORD\"\n",
    "bdhost = \"HOST_FROM_AMAZON_RDS\"\n",
    "dbname = \"DBNAME\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "### 2 - Gps coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2 - gps coordinates - set destination list ### ----\n",
    "\n",
    "# set list of cities\n",
    "cities = [\"Le Mont-Saint-Michel\", \"Saint-Malo\", \"Bayeux\", \"Le Havre\", \"Rouen\", \"Paris\", \"Amiens\", \"Lille\",\n",
    "\"Strasbourg\", \"Orschwiller\", \"Colmar\", \"Eguisheim\", \"Besançon\", \"Dijon\", \"Annecy\", \"Grenoble\", \"Lyon\",\n",
    "\"Moustiers-Sainte-Marie\", \"Bormes-les-Mimosas\", \"Cassis\", \"Marseille\", \"Aix-en-Provence\", \"Avignon\", \"Uzès\",\n",
    "\"Nîmes\", \"Aigues-Mortes\", \"Saintes-Maries-de-la-Mer\", \"Collioure\", \"Carcassonne\", \"Foix\", \"Toulouse\",\n",
    "\"Montauban\", \"Biarritz\", \"Bayonne\", \"La Rochelle\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2 - gps coordinates - get coordinates ### ----\n",
    "\n",
    "# initialise variable to store information on cities\n",
    "data1 = pd.DataFrame(index = range(0,len(cities)), columns = [\"city_id\", \"city_name\", \"city_latitude\",\n",
    "    \"city_longitude\"])\n",
    "\n",
    "# get and store latitude and longitude from the API nominatim.org\n",
    "for i in range(0,len(cities)):\n",
    "\n",
    "    # get data\n",
    "    city_current = cities[i]\n",
    "    data_current =  requests.get(\"https://nominatim.openstreetmap.org/search?city=\" + city_current + \"&format=json\")\n",
    "    data_current = data_current.json()\n",
    "\n",
    "    # store information\n",
    "    data1.loc[i,\"city_id\"] = i+1\n",
    "    data1.loc[i,\"city_name\"] = city_current\n",
    "    data1.loc[i,\"city_latitude\"] = data_current[0][\"lat\"]\n",
    "    data1.loc[i,\"city_longitude\"] = data_current[0][\"lon\"]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "### 3 - Weather forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3 - weather forecast - get data ### ----\n",
    "\n",
    "# copy data for safety\n",
    "data2 = data1.copy()\n",
    "\n",
    "# initialize columns to store mean temperature and mean probability of precipitation\n",
    "data2[\"city_temperature\"] = np.nan\n",
    "data2[\"city_precipitation\"] = np.nan\n",
    "\n",
    "# get and store weather data from the API openweathermap.org\n",
    "for i in range(0,data1.shape[0]):\n",
    "\n",
    "    # get data\n",
    "    data_current =  requests.get(\"https://api.openweathermap.org/data/2.5/forecast?lat=\" + \n",
    "        str(data2.loc[i,\"city_latitude\"]) + \"&lon=\" + str(data2.loc[i,\"city_longitude\"]) + \n",
    "        \"&appid=\" + key_openweather + \"&units=metric\")\n",
    "    data_current = data_current.json()\n",
    "\n",
    "    # initialise temporary variables\n",
    "    temperature_temp = []\n",
    "    precipitation_temp = []\n",
    "\n",
    "    # store information for 5 next days\n",
    "    for j in range(0,len(data_current[\"list\"])):\n",
    "        temperature_temp.append(data_current[\"list\"][j][\"main\"][\"temp\"])\n",
    "        precipitation_temp.append(data_current[\"list\"][j][\"pop\"])\n",
    "    \n",
    "    # store summary data\n",
    "    data2.loc[i,\"city_temperature\"] = np.mean(temperature_temp)\n",
    "    data2.loc[i,\"city_precipitation\"] = np.mean(precipitation_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3 - weather forecast - save data ### ----\n",
    "\n",
    "# rename and save data\n",
    "data2.to_csv(\"cnm_bloc1_data1_weather.csv\", index = False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "### 4 - Hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 - hotels - get booking.com urls for hotels in each city ### ----\n",
    "\n",
    "# run python script to get and save urls\n",
    "!python cnm_bloc1_scraping1.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 - hotels - get hotel info for each city ### ----\n",
    "\n",
    "# run python script to get and save hotel info\n",
    "!python cnm_bloc1_scraping2.py\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "### 5 - Data compilation and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5 - data compilation and cleaning - compile data ### ----\n",
    "\n",
    "# open saved files and get data\n",
    "data_weather = pd.read_csv(\"cnm_bloc1_data1_weather.csv\")\n",
    "file_urls = open(\"cnm_bloc1_data2_urls.json\")\n",
    "file_urls = json.load(file_urls)\n",
    "data_urls = pd.DataFrame(file_urls)\n",
    "file_hotels = open(\"cnm_bloc1_data3_hotels.json\")\n",
    "file_hotels = json.load(file_hotels)\n",
    "data_hotels = pd.DataFrame(file_hotels)\n",
    "\n",
    "# initialize dataframe to fit city and weather info to hotel info\n",
    "data_cities = pd.DataFrame(np.NaN, index = range(0,data_hotels.shape[0]), columns = data_weather.columns)\n",
    "\n",
    "# get unique cities\n",
    "cities_unique = data_weather[\"city_name\"].unique()\n",
    "\n",
    "# fill new dataframe\n",
    "for city in cities_unique:\n",
    "\n",
    "    # get masks for current city\n",
    "    mask1 = data_hotels[\"city_name\"] == city\n",
    "    mask2 = data_weather[\"city_name\"] == city\n",
    "    \n",
    "    # fill with weather data\n",
    "    data_cities.loc[mask1,\"city_id\"] = data_weather.loc[mask2,\"city_id\"].values[0]\n",
    "    data_cities.loc[mask1,\"city_name\"] = data_weather.loc[mask2,\"city_name\"].values[0]\n",
    "    data_cities.loc[mask1,\"city_latitude\"] = data_weather.loc[mask2,\"city_latitude\"].values[0]\n",
    "    data_cities.loc[mask1,\"city_longitude\"] = data_weather.loc[mask2,\"city_longitude\"].values[0]\n",
    "    data_cities.loc[mask1,\"city_temperature\"] = data_weather.loc[mask2,\"city_temperature\"].values[0]\n",
    "    data_cities.loc[mask1,\"city_precipitation\"] = data_weather.loc[mask2,\"city_precipitation\"].values[0]\n",
    "\n",
    "# drop city name in data_hotels and compile data\n",
    "data_hotels = data_hotels.drop([\"city_name\"], axis = 1)\n",
    "data_final = pd.concat([data_cities, data_hotels], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5 - data compilation and cleaning - clean data ### ----\n",
    "\n",
    "# part 1 - fix inconsistencies in city names\n",
    "\n",
    "# get index of rows with missing values in city info\n",
    "index_nan = data_final.loc[data_final[\"city_name\"].isnull(),:].index\n",
    "\n",
    "# get columns with missing values\n",
    "columns_nan = data_weather.columns\n",
    "\n",
    "# loop through rows\n",
    "for i in index_nan:\n",
    "\n",
    "    # get url of the hotel\n",
    "    url_current = data_final.loc[i,\"hotel_url\"]\n",
    "\n",
    "    # get city corresponding to that url\n",
    "    city_current = data_urls.loc[data_urls[\"url\"] == url_current,\"city\"].values[0]\n",
    "\n",
    "    # fill dataframe with info from data_weather\n",
    "    data_final.loc[i,columns_nan] = data_weather.loc[data_weather[\"city_name\"] == city_current,:].values[0]\n",
    "\n",
    "\n",
    "# part 2 - fix formatting issues\n",
    "\n",
    "# fix hotel score \n",
    "data_final.loc[data_final[\"hotel_score\"].isnull(),\"hotel_score\"] = np.NaN\n",
    "data_final[\"hotel_score\"] = data_final[\"hotel_score\"].str.replace(\",\",\".\")\n",
    "data_final.loc[data_final[\"hotel_score\"].notnull(),\"hotel_score\"] = [\"\".join(char for char in score \n",
    "    if char in set(\"0123456789.\")) for score in data_final[\"hotel_score\"] if type(score) == str]\n",
    "data_final.loc[data_final[\"hotel_score\"] == \"\",\"hotel_score\"] = np.NaN\n",
    "data_final[\"hotel_score\"] = data_final[\"hotel_score\"].astype(float)\n",
    "\n",
    "# fix hotel latitude and longitude\n",
    "data_final[\"hotel_latitude\"] = data_final[\"hotel_latitude\"].astype(float)\n",
    "data_final[\"hotel_longitude\"] = data_final[\"hotel_longitude\"].astype(float)\n",
    "\n",
    "# strip brackets in hotel descriptions (stored as lists)\n",
    "data_final[\"hotel_description\"] = [desc[0] for desc in data_final[\"hotel_description\"]]\n",
    "\n",
    "\n",
    "# part 3 - drop rows containing missing values in hotel score and select top-20 accomodations\n",
    "\n",
    "# drop accomodation if no score available\n",
    "index_drop = data_final.loc[data_final[\"hotel_score\"].isnull(),:].index\n",
    "data_final = data_final.drop(index_drop, axis = 0)\n",
    "\n",
    "# get unique cities\n",
    "cities_unique = data_final[\"city_name\"].unique()\n",
    "\n",
    "# initialise index to store index of accomodations to keep\n",
    "index_keep = [] \n",
    "\n",
    "# loop through cities\n",
    "for city in cities_unique:\n",
    "\n",
    "    # get data for current city\n",
    "    data_current = data_final.loc[data_final[\"city_name\"] == city,:]\n",
    "\n",
    "    # sort by score and get index\n",
    "    index_current = list(data_current.sort_values(\"hotel_score\", ascending = False).index)\n",
    "    index_keep += index_current[0:20]\n",
    "\n",
    "# select top-20 per city based on score\n",
    "data_final = data_final.loc[index_keep,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5 - data compilation and cleaning - check cleaning ### ----\n",
    "\n",
    "# print shape of data\n",
    "print(\"Number of rows: {}\".format(data_final.shape[0]))\n",
    "print(\"Number of columns: {}\".format(data_final.shape[1]))\n",
    "print()\n",
    "\n",
    "# display dataset\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Dataset display: \")\n",
    "display(data_final.head())\n",
    "print()\n",
    "\n",
    "# check wether some columns are full of NaNs\n",
    "column_nan_full = data_final.columns[data_final.isnull().all()]\n",
    "column_nb = len(column_nan_full)\n",
    "\n",
    "# get percentage of missing values in columns\n",
    "percent_nan_col = data_final.isnull().sum() / data_final.shape[0] * 100\n",
    "\n",
    "# print report\n",
    "print(\"COLUMNS\")\n",
    "print(\"{} columns out of {} are fully filled with missing values\".format(column_nb,data_final.shape[1]))\n",
    "print(\"Percentage of missing values per column:\\n{}\".format(percent_nan_col))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5 - data compilation and cleaning - save data ### ----\n",
    "\n",
    "# rename and save data\n",
    "data_final.to_csv(\"cnm_bloc1_data4_final_dataset.csv\", index = False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "### 6 - Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6 - maps - get data ### ----\n",
    "\n",
    "# load clean dataset\n",
    "data_plot = pd.read_csv(\"cnm_bloc1_data4_final_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6 - maps - plot destination overview ### ----\n",
    "\n",
    "# get unique cities\n",
    "cities_unique = data_plot[\"city_name\"].unique()\n",
    "\n",
    "# create dataframe to store unique data\n",
    "data_fig1 = pd.DataFrame(index = range(0,len(cities_unique)), \n",
    "    columns = [\"city\",\"temperature\",\"rain_proba\",\"latitude\",\"longitude\"])\n",
    "\n",
    "# get data for each city\n",
    "for i in range(0, data_fig1.shape[0]):\n",
    "\n",
    "    # get current city\n",
    "    city_current = cities_unique[i]\n",
    "\n",
    "    # get current data\n",
    "    data_current = data_plot.loc[data_plot[\"city_name\"] == city_current,:].reset_index(drop = True)\n",
    "\n",
    "    # fill dataframe\n",
    "    data_fig1.loc[i,\"city\"] = city_current\n",
    "    data_fig1.loc[i,\"latitude\"] = data_current.loc[0,\"city_latitude\"]\n",
    "    data_fig1.loc[i,\"longitude\"] = data_current.loc[0,\"city_longitude\"]\n",
    "    data_fig1.loc[i,\"temperature\"] = data_current.loc[0,\"city_temperature\"]\n",
    "    data_fig1.loc[i,\"rain_proba\"] = data_current.loc[0,\"city_precipitation\"]\n",
    "\n",
    "data_fig1[\"temperature\"] = data_fig1[\"temperature\"].astype(float)\n",
    "data_fig1[\"rain_proba\"] = data_fig1[\"rain_proba\"].astype(float)\n",
    "\n",
    "# plot destinations\n",
    "fig1 = px.scatter_mapbox(\n",
    "    data_fig1, \n",
    "    lat = \"latitude\", \n",
    "    lon = \"longitude\", \n",
    "    color = \"rain_proba\",\n",
    "    size = \"temperature\",\n",
    "    size_max = 15,\n",
    "    color_continuous_scale = px.colors.diverging.Portland)\n",
    "\n",
    "# update layout\n",
    "fig1.update_layout(\n",
    "        title_text = \"Figure 1. Overview of destinations\",\n",
    "        title_x = 0.5,\n",
    "        title_y = 0.95,\n",
    "        title_font_size = 18,\n",
    "        plot_bgcolor = \"rgba(0,0,0,0)\",\n",
    "        paper_bgcolor = \"rgb(232,232,232)\",\n",
    "        width = 800,\n",
    "        height = 600)\n",
    "fig1.update_mapboxes(\n",
    "    style = \"carto-positron\",\n",
    "    zoom = 4)\n",
    "\n",
    "fig1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6 - maps - plot top-5 destination ### ----\n",
    "\n",
    "# get top-5 destinations based on rain probability\n",
    "data_fig1[\"rain_proba\"] = data_fig1[\"rain_proba\"].round(2)\n",
    "data_fig1[\"temperature\"] = data_fig1[\"temperature\"].round(1)\n",
    "data_fig1 = data_fig1.sort_values([\"rain_proba\",\"temperature\"], ascending = [True, False]).reset_index(drop = True)\n",
    "cities_top = data_fig1.loc[0:5,\"city\"].values\n",
    "\n",
    "# extract data\n",
    "data_fig2 = data_plot.loc[data_plot[\"city_name\"].isin(cities_top),:]\n",
    "\n",
    "# plot top-1 destination\n",
    "fig21 = px.scatter_mapbox(\n",
    "    data_fig2.loc[data_fig2[\"city_name\"] == cities_top[0]], \n",
    "    lat = \"hotel_latitude\", \n",
    "    lon = \"hotel_longitude\", \n",
    "    color = \"hotel_score\",\n",
    "    size = [1] * data_fig2.loc[data_fig2[\"city_name\"] == cities_top[0]].shape[0],\n",
    "    color_continuous_scale = px.colors.diverging.Portland)\n",
    "\n",
    "# update layout\n",
    "fig21.update_layout(\n",
    "        title_text = \"Figure 2-1. Recommended hotels in \" + cities_top[0],\n",
    "        title_x = 0.5,\n",
    "        title_y = 0.95,\n",
    "        title_font_size = 18,\n",
    "        plot_bgcolor = \"rgba(0,0,0,0)\",\n",
    "        paper_bgcolor = \"rgb(232,232,232)\",\n",
    "        width = 800,\n",
    "        height = 600)\n",
    "fig21.update_mapboxes(\n",
    "    style = \"carto-positron\",\n",
    "    zoom = 11)\n",
    "\n",
    "# plot top-2 destination\n",
    "fig22 = px.scatter_mapbox(\n",
    "    data_fig2.loc[data_fig2[\"city_name\"] == cities_top[1]], \n",
    "    lat = \"hotel_latitude\", \n",
    "    lon = \"hotel_longitude\", \n",
    "    color = \"hotel_score\",\n",
    "    size = [1] * data_fig2.loc[data_fig2[\"city_name\"] == cities_top[1]].shape[0],\n",
    "    color_continuous_scale = px.colors.diverging.Portland)\n",
    "\n",
    "# update layout\n",
    "fig22.update_layout(\n",
    "        title_text = \"Figure 2-2. Recommended hotels in \" + cities_top[1],\n",
    "        title_x = 0.5,\n",
    "        title_y = 0.95,\n",
    "        title_font_size = 18,\n",
    "        plot_bgcolor = \"rgba(0,0,0,0)\",\n",
    "        paper_bgcolor = \"rgb(232,232,232)\",\n",
    "        width = 800,\n",
    "        height = 600)\n",
    "fig22.update_mapboxes(\n",
    "    style = \"carto-positron\",\n",
    "    zoom = 11)\n",
    "\n",
    "# plot top-3 destination\n",
    "fig23 = px.scatter_mapbox(\n",
    "    data_fig2.loc[data_fig2[\"city_name\"] == cities_top[2]], \n",
    "    lat = \"hotel_latitude\", \n",
    "    lon = \"hotel_longitude\", \n",
    "    color = \"hotel_score\",\n",
    "    size = [1] * data_fig2.loc[data_fig2[\"city_name\"] == cities_top[2]].shape[0],\n",
    "    color_continuous_scale = px.colors.diverging.Portland)\n",
    "\n",
    "# update layout\n",
    "fig23.update_layout(\n",
    "        title_text = \"Figure 2-3. Recommended hotels in \" + cities_top[2],\n",
    "        title_x = 0.5,\n",
    "        title_y = 0.95,\n",
    "        title_font_size = 18,\n",
    "        plot_bgcolor = \"rgba(0,0,0,0)\",\n",
    "        paper_bgcolor = \"rgb(232,232,232)\",\n",
    "        width = 800,\n",
    "        height = 600)\n",
    "fig23.update_mapboxes(\n",
    "    style = \"carto-positron\",\n",
    "    zoom = 11)\n",
    "\n",
    "# plot top-4 destination\n",
    "fig24 = px.scatter_mapbox(\n",
    "    data_fig2.loc[data_fig2[\"city_name\"] == cities_top[3]], \n",
    "    lat = \"hotel_latitude\", \n",
    "    lon = \"hotel_longitude\", \n",
    "    color = \"hotel_score\",\n",
    "    size = [1] * data_fig2.loc[data_fig2[\"city_name\"] == cities_top[3]].shape[0],\n",
    "    color_continuous_scale = px.colors.diverging.Portland)\n",
    "\n",
    "# update layout\n",
    "fig24.update_layout(\n",
    "        title_text = \"Figure 2-4. Recommended hotels in \" + cities_top[3],\n",
    "        title_x = 0.5,\n",
    "        title_y = 0.95,\n",
    "        title_font_size = 18,\n",
    "        plot_bgcolor = \"rgba(0,0,0,0)\",\n",
    "        paper_bgcolor = \"rgb(232,232,232)\",\n",
    "        width = 800,\n",
    "        height = 600)\n",
    "fig24.update_mapboxes(\n",
    "    style = \"carto-positron\",\n",
    "    zoom = 11)\n",
    "\n",
    "# plot top-5 destination\n",
    "fig25 = px.scatter_mapbox(\n",
    "    data_fig2.loc[data_fig2[\"city_name\"] == cities_top[4]], \n",
    "    lat = \"hotel_latitude\", \n",
    "    lon = \"hotel_longitude\", \n",
    "    color = \"hotel_score\",\n",
    "    size = [1] * data_fig2.loc[data_fig2[\"city_name\"] == cities_top[4]].shape[0],\n",
    "    color_continuous_scale = px.colors.diverging.Portland)\n",
    "\n",
    "# update layout\n",
    "fig25.update_layout(\n",
    "        title_text = \"Figure 2-5. Recommended hotels in \" + cities_top[4],\n",
    "        title_x = 0.5,\n",
    "        title_y = 0.95,\n",
    "        title_font_size = 18,\n",
    "        plot_bgcolor = \"rgba(0,0,0,0)\",\n",
    "        paper_bgcolor = \"rgb(232,232,232)\",\n",
    "        width = 800,\n",
    "        height = 600)\n",
    "fig25.update_mapboxes(\n",
    "    style = \"carto-positron\",\n",
    "    zoom = 11)\n",
    "\n",
    "fig21.show()\n",
    "fig22.show()\n",
    "fig23.show()\n",
    "fig24.show()\n",
    "fig25.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "### 7 - Data storage and ETL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "### 7 - data storage and etl - data storage ### ----\n",
    "\n",
    "# final cleaned data (cnm_bloc1_data4_final_dataset.csv) stored in a s3 bucket\n",
    "\n",
    "```\n",
    "![alt text](cnm_bloc1_s3_bucket.png \"S3 bucket with cleaned data\")\n",
    "\n",
    "```python\n",
    "\n",
    "# database instance in rds \n",
    "\n",
    "```\n",
    "![alt text](cnm_bloc1_sql_database.png \"RDS database instance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7 - data storage and etl - etl ### ----\n",
    "\n",
    "# extract data from s3 bucket\n",
    "session = boto3.Session(aws_access_key_id, aws_secret_access_key)\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file('cnm-bloc1', 'cnm_bloc1_data4_final_dataset.csv', 'my_file.csv')\n",
    "\n",
    "# transform into dataframe\n",
    "my_data = pd.read_csv(\"my_file.csv\")\n",
    "\n",
    "# load to database\n",
    "engine = create_engine(\"postgresql+psycopg2://{dbuser}:{dbpass}@{dbhost}/{dbname}\", echo = True)\n",
    "my_data.to_sql(\"my_final_table\", engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
